@misc{lane_natural_2019,
	title = {Natural language processing in action : understanding, analyzing, and generating text with {Python}},
	abstract = {Natural Language Processing in Action is your guide to building machines that can read and interpret human language. In it, you’ll use readily available Python packages to capture the meaning in text and react accordingly. The book expands traditional NLP approaches to include neural networks, modern deep learning algorithms, and generative techniques as you tackle real-world problems like extracting dates and names, composing text, and answering free-form questions.},
	language = {eng},
	publisher = {Manning},
	author = {Lane, Hobson},
	year = {2019},
	note = {Edition: 1st edition.
ISBN: 1-63835-689-0
Place: Shelter Island, New York},
	keywords = {Natural language processing (Computer science), Python (Computer program language)},
}


@article{harris_array_2020,
	title = {Array programming with {NumPy}},
	volume = {585},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/s41586-020-2649-2},
	doi = {10.1038/s41586-020-2649-2},
	abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
	number = {7825},
	journal = {Nature},
	author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del Río, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	month = sep,
	year = {2020},
	pages = {357--362},
}

@article{pedregosa_scikit-learn_nodate,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simpliﬁed BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	language = {en},
	journal = {MACHINE LEARNING IN PYTHON},
	author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
	file = {Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:/Users/jesselang/Zotero/storage/C8GEQNPN/Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}


@misc{bird_natural_nodate,
	title = {Natural {Language} {Processing} with {Python} [{Book}]},
	url = {https://www.oreilly.com/library/view/natural-language-processing/9780596803346/},
	abstract = {This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and … - Selection from Natural Language Processing with Python [Book]},
	language = {en},
	urldate = {2023-10-28},
	author = {Bird, Steven and Klein, Ewan and Loper, Edward},
	note = {ISBN: 9780596516499},
	file = {Snapshot:/Users/jesselang/Zotero/storage/5RHGRK4E/9780596803346.html:text/html},
}

@misc{sklearn_dtt,
author = {Scikit-learn},
title = {Decision Trees},
howpublished = {\url{https://scikit-learn/stable/modules/tree.html}},
note = {Accessed: 2024-02-22},
year = {2024}
}

@misc{sklearn_ttt,
author = {Scikit-learn},
title = {Train-Test Split},
howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}},
note = {Accessed: 2024-03-14},
year = {2024}
}

@misc{openai_gpt3,
author = {OpenAI GPT-3},
title = {Chat GPT-3},
howpublished = {\url{https://chat.openai.com}},
note = {Accessed: 2024-02-18},
year = {2024}
}

@misc{text_dataset,
author = {Sunil Thite},
title = {Text Document Classification Dataset},
howpublished = {\url{https://www.kaggle.com/datasets/sunilthite/text-document-classification-dataset}},
note = {Accessed: 2024-02-18},
year = {2024}
}

@article{ali_data_2014,
	title = {Data normalization and standardization: a technical report},
	volume = {1},
	number = {1},
	journal = {Mach Learn Tech Rep},
	author = {Ali, Peshawa Jamal Muhammad and Faraj, Rezhna Hassan and Koya, Erbil and Ali, Peshawa J Muhammad and Faraj, Rezhna H},
	year = {2014},
	pages = {1--6},
}

@inproceedings{sen_supervised_2020,
	title = {Supervised classification algorithms in machine learning: {A} survey and review},
	booktitle = {Emerging {Technology} in {Modelling} and {Graphics}: {Proceedings} of {IEM} {Graph} 2018},
	publisher = {Springer},
	author = {Sen, Pratap Chandra and Hajra, Mahimarnab and Ghosh, Mitadru},
	year = {2020},
	pages = {99--111},
}

@article{madhulatha_overview_2012,
	title = {An overview on clustering methods},
	journal = {arXiv preprint arXiv:1205.1117},
	author = {Madhulatha, T Soni},
	year = {2012},
}

@book{gulli_deep_2017,
	title = {Deep learning with {Keras}},
	publisher = {Packt Publishing Ltd},
	author = {Gulli, Antonio and Pal, Sujit},
	year = {2017},
}

@article{kowsari_text_2019,
	title = {Text {Classification} {Algorithms}: {A} {Survey}},
	volume = {10},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/10/4/150},
	doi = {10.3390/info10040150},
	abstract = {In recent years, there has been an exponential growth in the number of complex documents and texts that require a deeper understanding of machine learning methods to be able to accurately classify texts in many applications. Many machine learning approaches have achieved surpassing results in natural language processing. The success of these learning algorithms relies on their capacity to understand complex models and non-linear relationships within data. However, finding suitable structures, architectures, and techniques for text classification is a challenge for researchers. In this paper, a brief overview of text classification algorithms is discussed. This overview covers different text feature extractions, dimensionality reduction methods, existing algorithms and techniques, and evaluations methods. Finally, the limitations of each technique and their application in real-world problems are discussed.},
	number = {4},
	journal = {Information},
	author = {Kowsari, Kamran and Jafari Meimandi, Kiana and Heidarysafa, Mojtaba and Mendu, Sanjana and Barnes, Laura and Brown, Donald},
	year = {2019},
}

@article{aurangzeb_review_2010,
	title = {A {Review} of {Machine} {Learning} {Algorithms} for {Text}-{Documents} {Classification}},
	volume = {1},
	issn = {1798-2340},
	url = {http://www.jait.us/index.php?m=content&c=index&a=show&catid=160&id=856},
	doi = {10.4304/jait.1.1.1-1},
	language = {en},
	number = {1},
	urldate = {2024-01-05},
	journal = {Journal of Advances in Information Technology},
	author = {Aurangzeb, Khan and Baharum, Baharudin and Lam Hong, Lee and Khairullah, Khan},
	month = feb,
	year = {2010},
	pages = {1--1},
	file = {Fong - 2010 - Welcome Message from the Editor-in-Chief.pdf:/Users/jesselang/Zotero/storage/HQW2WRJ6/Fong - 2010 - Welcome Message from the Editor-in-Chief.pdf:application/pdf},
}


@phdthesis{helland_tackling_2023,
	title = {Tackling {Lower}-{Resource} {Language} {Challenges}: {A} {Comparative} {Study} of {Norwegian} {Pre}-{Trained} {BERT} {Models} and {Traditional} {Approaches} for {Football} {Article} {Paragraph} {Classification}},
	url = {https://home.simula.no/~paalh/students/EirikDuesundHelland-NMBU-2023.pdf},
	author = {Helland, Eirik Duesund},
	month = may,
	year = {2023},
}

@article{vijayarani_preprocessing_2015,
	title = {Preprocessing techniques for text mining-an overview},
	volume = {5},
	number = {1},
	journal = {International Journal of Computer Science \& Communication Networks},
	author = {Vijayarani, S and Ilamathi, Ms J and Nithya, Ms and {others}},
	year = {2015},
	pages = {7--16},
}

@article{tabassum_survey_2020,
	title = {A survey on text pre-processing \& feature extraction techniques in natural language processing},
	volume = {7},
	number = {06},
	journal = {International Research Journal of Engineering and Technology (IRJET)},
	author = {Tabassum, Ayisha and Patil, Rajendra R},
	year = {2020},
	pages = {4864--4867},
}
