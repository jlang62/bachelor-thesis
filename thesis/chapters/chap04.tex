\chapter{Results}

The results presented in this chapter are the outcomes obtained by applying pre-processing techniques and machine learning models to the dataset for multi-class classification. Chapter 5 goes into further depth about the findings. Each of the model’s runtimes, performance metrics (accuracy), and findings of the data pre-processing steps are included in the results. 

\section{Data Pre-processing}
\subsection{Label Distribution}

\fig{img/distributon_labels}{Distributon of the labels}{fig:dist-labels}{0.65}

Figure~\ref{fig:dist-labels} shows the distribution of the labels in the BBC dataset. The labels represent the categories 0: politics, 1: sport, 2: technology, 3: entertainment, 4: business. The distribution is measured in the total amount of documents per label.

As can be seen in Figure~\ref{fig:dist-labels}, there is an unequal distribution of the categories, where the sports and business sections carry the most weight. Whereas the other three labels have around 20\% less data available.

\subsection{Token length distribution}

\fig{img/token_length}{Distributon of the token length}{fig:dist-token-length}{0.65}

Figure~\ref{fig:dist-token-length} illustrates the distribution of token lengths per label within the dataset using box plots with outliers. Each box plot represents the distribution of token lengths, with the box indicating the interquartile range and the median, while the outer ends extend to the minimum and maximum values.

This visualization provides a comprehensive view of the variability in token lengths present in the textual data. By examining the box plots, we can discern the typical range of token lengths as well as the presence of outliers or extreme values.

\subsection{Label insights}

\fig{img/topwords}{Top 10 words of the politics and technology category}{fig:top-words}{1}

Figure~\ref{fig:top-words} presents the top 10 words for each of the two labels, "politics" and "technology." This visualization offers a concise representation of the most frequent words associated with each category, providing a quick overview of the predominant themes within the dataset.

By presenting the most commonly occurring words, this figure aids in understanding the lexical characteristics of the politics and technology categories, serving as a useful reference for subsequent analysis and interpretation of the textual data.

\section{Model Performance}

By analyzing key metrics like accuracy and runtime, it provides important insights into each model's effectiveness and computational efficiency. This evaluation process guides our decisions in selecting the most suitable models for practical applications.

\break

\subsection{Accuracy}

\fig{img/accuracy}{Accuracy of the models}{fig:perf-acc}{0.7}

Figure~\ref{fig:perf-acc} displays the evaluation of different classification models. In this visualization, each model's accuracy score is shown, providing a clear comparison of their performance in classifying textual documents across different categories or classes. Logistic Regression and Support Vector Machine provided the most precise score with 0.97 accuracy, followed by Random Forest (0.96) and K-Nearest-Neighbour (0.92). Whereas the Decision Tree model came out as the least accurate model (0.81).

This information is crucial for determining the effectiveness and reliability of the classification algorithms employed in the study, aiding in model selection and optimization strategies.

\break

\subsection{Runtime}

\fig{img/runtime}{Runtime of the models}{fig:perf-runtime}{0.7}

Figure~\ref{fig:perf-runtime} displays the runtime of the classification models utilized in this study. Runtime refers to the time taken by each model to complete the classification task, from training to prediction, on the given dataset. The faster the model’s runtime is the more efficient it will be in production. Therefore is KNN (4.93 s) the quickest, Naïve Bayes (5.78 s) second, and Decision Tree (8.76 s) third. At the bottom of the ranking are the following models, SVM (98.27 s) and XGBoost (139.82 s).

This information is important for assessing the practical probability and scalability of the classification algorithms, particularly in real-world applications where computational efficiency is a significant consideration.
