\chapter{Theory}

Through an insight into relevant development in the field, various models, preprocessing methodologies, and evaluation metrics, this chapter aims to construct a theoretical framework for the thesis. Its objective is to empower the reader with the requisite understanding to contextualize the research outcomes and their significance.

\section{Natural Language Processing}

Natural Language Processing (NLP) is a branch of artificial intelligence and computer science, that deals with the interaction between computers and human language \citep{helland_tackling_2023}. It aims to enable machines to generate human language, process, and understand it. By employing a variety of techniques and different approaches, such as deep learning, rule-based systems, and statistical methods, is NLP capable of tackling different language-related tasks. The usage of it can be found in numerous areas, including machine translation, chatbots, text classification, and speech recognition \citep{helland_tackling_2023}.

\section{Machine Learning}

Machine learning refers to the development of computer programs that are learning from experience to complete and solve a certain task. The measurement of the performance is calculated by the ability to do so \citep{helland_tackling_2023}. A training dataset represents the “experience” that is acquired by machine learning models, which contains output and input pairs. From the analysis of these examples can the model recognize and generalize the patterns to new, unseen data. To simplify, can it be reflected in the process of human learning and adaptation to new scenarios. Common applications include fraud detection, self-driving cars, and personalized recommendations \citep{helland_tackling_2023}.

\section{Deep Learning}

Deep learning is a method that uses non-linear modules to transform the data at multiple levels of abstraction, allowing models to find patterns in the raw data \citep{helland_tackling_2023}. This suggests that deep learning models are discovering and learning different data features without the need for human interaction. Because of its universal learning, generalization potential, robustness, and scalability advantages, this can be used in a variety of applications without the need for precise feature engineering \citep{helland_tackling_2023}.

\section{Evaluation Metrics}

A machine learning model's performance is assessed using metrics. They are employed to evaluate the accuracy of the made predictions, to analyze the output of various models, and to fine-tune them for optimal performance \citep{helland_tackling_2023}. Different types of machine learning issues have various types of metrics available. The model selection process, the optimization procedure, and the overall understanding of the model's capabilities can all be impacted by the metrics chosen. Selecting the incorrect metrics might also result in a biased model, which aligns differently with the project's objectives \citep{helland_tackling_2023}.

\subsection{Accuracy}

One popular assessment metric for classification problems is “accuracy”. Out of all the samples in the prediction, it calculates the proportion of correctly classified samples \citep{helland_tackling_2023}. 

Accuracy = Number of correctly classified instances/ Total number of instances

For balanced datasets, accuracy works well since it presents a realistic picture of the model's capabilities and performance. When datasets are unbalanced, accuracy might be misleading and more difficult to interpret \citep{helland_tackling_2023}. This may be due to a single label in the dataset that accounts for the majority of the samples; therefore, reasonable accuracy can still be obtained by projecting all samples to the dominant label. This does not imply that the model is good because it ignores the less common but no less significant labels. Accuracy in multi-label classification only takes into account samples where every label is correctly classified. Because of this, using accuracy as a multi-label classification metric to evaluate the performance of multi-label models is more strict, less informative, and less desirable \citep{helland_tackling_2023}.