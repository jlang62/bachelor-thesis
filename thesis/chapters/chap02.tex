\chapter{Theory}

The theoretical basis of this thesis provides the necessary background to comprehend the research discussed in the following chapters. Through an insight of relevant development in the field, various models, preprocessing methodologies, and evaluation metrics, this chapter aims to construct a theoretical framework for the thesis. Its objective is to empower the reader with the requisite understanding to contextualize the research outcomes and their significance.

\section{Natural Language Processing}

Natural Language Processing (NLP) is a branch of computer science and artificial intelligence, that deals with the interaction between human language and computers. Its aim is to enable machines to generate human language, process and understand it. Through employing a variety of techniques and different approaches, such as deep learning, rule-based systems, and statistical methods, is NLP capable to tackle different language-related tasks. The usage of it can be found in numerous areas, including machine translation, chatbots, text classification, and speech recognition (Helland, 2023).

\section{Machine Learning}

Machine learning refers to the development of computer programs that are learning from experience to complete and solve a certain task. The measurement of the performance is calculated by the ability to do so. A training dataset represents the “experience” that is acquired by machine learning models, which contains output and input pairs. From the analysis of these examples can the model recognize and generalise the patterns to new, unseen data. To simplify, can it be reflected to the process of human learning and adaption to new scenarios. Common applications include fraud detection, self-driving cars and personalised recommendations (Helland, 2023).

\section{Deep Learning}

Deep learning is a method that uses non-linear modules to transform the data at multiple levels of abstraction, allowing models to find patterns in the raw data. This suggests that deep learning models are discovering and learning different data features without the need for human interaction. Because of its universal learning, generalization potential, robustness, and scalability advantages, this can be used in a variety of applications without the need for precise feature engineering (Helland, 2023).