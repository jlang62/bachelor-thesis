{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import nltk library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# import necessary libraries for text preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"The quick brown fox\"\n",
    "doc2 = \"Jumped over the lazy dog\"\n",
    "doc3 = \"The dog chased the fox\"\n",
    "\n",
    "corpus = [doc1, doc2, doc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 8, 'quick': 7, 'brown': 0, 'fox': 3, 'jumped': 4, 'over': 6, 'lazy': 5, 'dog': 2, 'chased': 1}\n",
      "[[1 0 0 1 0 0 0 1 1]\n",
      " [0 0 1 0 1 1 1 0 1]\n",
      " [0 1 1 1 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# create bow model\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(corpus)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(corpus)\n",
    "# summarize encoded vector\n",
    "print(vector.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brown  chased  dog  fox  jumped  lazy  over  quick  the\n",
      "0      1       0    0    1       0     0     0      1    1\n",
      "1      0       0    1    0       1     1     1      0    1\n",
      "2      0       1    1    1       0     0     0      0    2\n"
     ]
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names_out()\n",
    "df_words = pd.DataFrame(vector.toarray(), columns=words)\n",
    "print(df_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 8, 'quick': 7, 'brown': 0, 'fox': 3, 'jumped': 4, 'over': 6, 'lazy': 5, 'dog': 2, 'chased': 1}\n",
      "[1.69314718 1.69314718 1.28768207 1.28768207 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.        ]\n",
      "[[0.5844829  0.         0.         0.44451431 0.         0.\n",
      "  0.         0.5844829  0.34520502]\n",
      " [0.         0.         0.38376993 0.         0.50461134 0.50461134\n",
      "  0.50461134 0.         0.29803159]\n",
      " [0.         0.53058735 0.40352536 0.40352536 0.         0.\n",
      "  0.         0.         0.62674687]]\n",
      "      brown    chased       dog       fox    jumped      lazy      over  \\\n",
      "0  0.584483  0.000000  0.000000  0.444514  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.383770  0.000000  0.504611  0.504611  0.504611   \n",
      "2  0.000000  0.530587  0.403525  0.403525  0.000000  0.000000  0.000000   \n",
      "\n",
      "      quick       the  \n",
      "0  0.584483  0.345205  \n",
      "1  0.000000  0.298032  \n",
      "2  0.000000  0.626747  \n"
     ]
    }
   ],
   "source": [
    "# create tf-idf model and the dataframe with words\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(corpus)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(corpus)\n",
    "# summarize encoded vector\n",
    "print(vector.toarray())\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "df_words = pd.DataFrame(vector.toarray(), columns=words)\n",
    "print(df_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
